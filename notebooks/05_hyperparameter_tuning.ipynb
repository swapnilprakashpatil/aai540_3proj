{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eeed3ff",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning: Isolation Forest Optimization\n",
    "\n",
    "**Project:** AAI-540 Machine Learning Operations - Final Team Project  \n",
    "**Context:** Continuation of notebook 04.1 - Isolation Forest Anomaly Detection  \n",
    "**Objective:** Optimize Isolation Forest hyperparameters using Grid Search and Randomized Search to improve anomaly detection performance\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Data Loading](#setup)\n",
    "2. [Baseline Model Performance](#baseline)\n",
    "3. [Hyperparameter Search Space Definition](#search-space)\n",
    "4. [Grid Search Optimization](#grid-search)\n",
    "5. [Randomized Search Optimization](#random-search)\n",
    "6. [Performance Comparison & Analysis](#comparison)\n",
    "7. [Final Model Training with Optimal Parameters](#final-model)\n",
    "8. [Model Validation & Evaluation](#validation)\n",
    "9. [Summary & Outputs](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f3f5a0",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n",
    "\n",
    "Load dependencies and restore configuration from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import randint, uniform\n",
    "from utils.visualizations import ModelVisualizer\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Initialize visualizer\n",
    "model_viz = ModelVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364eb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored variables from previous notebooks\n",
    "%store -r bucket\n",
    "%store -r region\n",
    "%store -r database_name\n",
    "%store -r table_name_parquet\n",
    "%store -r df\n",
    "\n",
    "if 'df' not in dir() or df is None:\n",
    "    raise NameError(\"Missing required variable 'df'. Run notebook 02 first.\")\n",
    "    \n",
    "print(f\"Region: {region} | Bucket: {bucket} | Database: {database_name}\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401949a",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Prepare features for hyperparameter tuning using the same preprocessing pipeline as notebook 04.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset\n",
    "df_payments = df.copy()\n",
    "\n",
    "# Select numeric features for anomaly detection\n",
    "numeric_cols = df_payments.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Exclude identifier and non-relevant columns\n",
    "cols_to_exclude = [\n",
    "    'EventTime', 'covered_recipient_profile_id', 'index',\n",
    "    'teaching_hospital_id', 'covered_recipient_npi',\n",
    "    'recipient_zip_code', 'recipient_province', 'recipient_postal_code'\n",
    "]\n",
    "\n",
    "numeric_features = [col for col in numeric_cols \n",
    "                   if col not in cols_to_exclude \n",
    "                   and not any(x in col.lower() for x in ['_id', '_code', '_province', '_postal'])]\n",
    "\n",
    "# Create feature matrix\n",
    "X = df_payments[numeric_features].copy().astype(float)\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Remove columns with excessive missing values (>50%)\n",
    "missing_pct = (X.isnull().sum() / len(X)) * 100\n",
    "cols_to_keep = missing_pct[missing_pct <= 50].index.tolist()\n",
    "X = X[cols_to_keep]\n",
    "\n",
    "# Handle outliers using IQR method\n",
    "for col in X.columns:\n",
    "    q1, q3 = X[col].quantile(0.25), X[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    X[col] = X[col].clip(lower=q1 - 3*iqr, upper=q3 + 3*iqr)\n",
    "\n",
    "# Fill remaining missing values with median\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Features prepared: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b662412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b9258",
   "metadata": {},
   "source": [
    "## 2. Baseline Model Performance\n",
    "\n",
    "Train the baseline Isolation Forest model with default parameters from notebook 04.1 to establish performance benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7918bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline hyperparameters from notebook 04.1\n",
    "baseline_params = {\n",
    "    'n_estimators': 200,\n",
    "    'contamination': 0.05,\n",
    "    'max_samples': 'auto',\n",
    "    'max_features': 1.0,\n",
    "    'bootstrap': False,\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "start_time = time.time()\n",
    "\n",
    "baseline_model = IsolationForest(\n",
    "    n_estimators=baseline_params['n_estimators'],\n",
    "    contamination=baseline_params['contamination'],\n",
    "    max_samples=baseline_params['max_samples'],\n",
    "    max_features=baseline_params['max_features'],\n",
    "    bootstrap=baseline_params['bootstrap'],\n",
    "    random_state=baseline_params['random_state'],\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train)\n",
    "baseline_train_time = time.time() - start_time\n",
    "\n",
    "print(f\"Baseline training completed in {baseline_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model\n",
    "baseline_train_scores = baseline_model.decision_function(X_train)\n",
    "baseline_test_scores = baseline_model.decision_function(X_test)\n",
    "baseline_train_preds = baseline_model.predict(X_train)\n",
    "baseline_test_preds = baseline_model.predict(X_test)\n",
    "\n",
    "baseline_train_anomalies = (baseline_train_preds == -1).sum()\n",
    "baseline_test_anomalies = (baseline_test_preds == -1).sum()\n",
    "\n",
    "# Calculate anomaly score statistics\n",
    "baseline_score_mean = baseline_test_scores.mean()\n",
    "baseline_score_std = baseline_test_scores.std()\n",
    "baseline_score_range = baseline_test_scores.max() - baseline_test_scores.min()\n",
    "\n",
    "print(\"\\nBaseline Performance:\")\n",
    "print(f\"  Train Anomalies: {baseline_train_anomalies:,}/{len(X_train):,} ({baseline_train_anomalies/len(X_train)*100:.2f}%)\")\n",
    "print(f\"  Test Anomalies: {baseline_test_anomalies:,}/{len(X_test):,} ({baseline_test_anomalies/len(X_test)*100:.2f}%)\")\n",
    "print(f\"\\n  Score Statistics (Test):\")\n",
    "print(f\"    Mean: {baseline_score_mean:.6f}\")\n",
    "print(f\"    Std: {baseline_score_std:.6f}\")\n",
    "print(f\"    Range: {baseline_score_range:.6f}\")\n",
    "print(f\"    Min: {baseline_test_scores.min():.6f}\")\n",
    "print(f\"    Max: {baseline_test_scores.max():.6f}\")\n",
    "print(f\"\\n  Training Time: {baseline_train_time:.2f}s\")\n",
    "\n",
    "# Store baseline metrics for comparison\n",
    "baseline_metrics = {\n",
    "    'train_time': baseline_train_time,\n",
    "    'train_anomalies': baseline_train_anomalies,\n",
    "    'test_anomalies': baseline_test_anomalies,\n",
    "    'score_mean': baseline_score_mean,\n",
    "    'score_std': baseline_score_std,\n",
    "    'score_range': baseline_score_range\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01bd884",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Search Space Definition\n",
    "\n",
    "Define the hyperparameter search space for Isolation Forest optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom scoring function for anomaly detection\n",
    "# We want to maximize the separation between anomalies and normal points\n",
    "def anomaly_score_separation(estimator, X):\n",
    "    \"\"\"\n",
    "    Custom scoring function that measures the separation between\n",
    "    anomaly scores of detected anomalies and normal points.\n",
    "    Higher separation indicates better anomaly detection.\n",
    "    \"\"\"\n",
    "    scores = estimator.decision_function(X)\n",
    "    predictions = estimator.predict(X)\n",
    "    \n",
    "    anomaly_scores = scores[predictions == -1]\n",
    "    normal_scores = scores[predictions == 1]\n",
    "    \n",
    "    if len(anomaly_scores) == 0 or len(normal_scores) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate separation using mean difference normalized by std\n",
    "    separation = (normal_scores.mean() - anomaly_scores.mean()) / (scores.std() + 1e-10)\n",
    "    return separation\n",
    "\n",
    "# Create scorer\n",
    "anomaly_scorer = make_scorer(anomaly_score_separation, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search parameter grid (focused search around baseline)\n",
    "grid_param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'contamination': [0.03, 0.05, 0.07, 0.10],\n",
    "    'max_samples': ['auto', 256, 512, 1024],\n",
    "    'max_features': [0.7, 0.8, 0.9, 1.0],\n",
    "    'bootstrap': [False, True]\n",
    "}\n",
    "\n",
    "print(f\"Grid Search: {np.prod([len(v) for v in grid_param_grid.values()]):,} total combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search parameter distributions (broader exploration)\n",
    "random_param_dist = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'contamination': uniform(0.01, 0.15),\n",
    "    'max_samples': ['auto', 128, 256, 512, 1024, 2048],\n",
    "    'max_features': uniform(0.5, 0.5),  # 0.5 to 1.0\n",
    "    'bootstrap': [False, True]\n",
    "}\n",
    "\n",
    "n_iter_random = 50  # Number of random parameter combinations to try\n",
    "\n",
    "print(f\"Randomized Search: {n_iter_random} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8debb",
   "metadata": {},
   "source": [
    "## 4. Grid Search Optimization\n",
    "\n",
    "Perform exhaustive grid search to find optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search with reduced parameter grid for efficiency\n",
    "# Using a subset of the full grid to keep computation manageable\n",
    "grid_param_grid_reduced = {\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'contamination': [0.03, 0.05, 0.07],\n",
    "    'max_samples': ['auto', 512],\n",
    "    'max_features': [0.8, 1.0],\n",
    "    'bootstrap': [False, True]\n",
    "}\n",
    "\n",
    "print(f\"Starting Grid Search with {np.prod([len(v) for v in grid_param_grid_reduced.values()])} combinations...\")\n",
    "\n",
    "grid_search_start = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=IsolationForest(random_state=42, n_jobs=1, verbose=0),\n",
    "    param_grid=grid_param_grid_reduced,\n",
    "    scoring=anomaly_scorer,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train)\n",
    "grid_search_time = time.time() - grid_search_start\n",
    "\n",
    "print(f\"Grid Search completed in {grid_search_time:.2f}s ({grid_search_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Grid Search results\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(f\"\\nBest Score: {grid_search.best_score_:.6f}\")\n",
    "print(f\"Best Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create results dataframe\n",
    "grid_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_results_df = grid_results_df.sort_values('rank_test_score')\n",
    "\n",
    "# Display top 10 parameter combinations\n",
    "print(\"\\nTop 10 Parameter Combinations:\")\n",
    "display_cols = ['rank_test_score', 'mean_test_score', 'std_test_score', 'mean_fit_time',\n",
    "                'param_n_estimators', 'param_contamination', 'param_max_samples', \n",
    "                'param_max_features', 'param_bootstrap']\n",
    "display(grid_results_df[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grid Search results\n",
    "fig = model_viz.plot_grid_search_results(grid_results_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e2054",
   "metadata": {},
   "source": [
    "## 5. Randomized Search Optimization\n",
    "\n",
    "Perform randomized search for broader parameter space exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting Randomized Search with {n_iter_random} iterations...\")\n",
    "\n",
    "random_search_start = time.time()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=IsolationForest(random_state=42, n_jobs=1, verbose=0),\n",
    "    param_distributions=random_param_dist,\n",
    "    n_iter=n_iter_random,\n",
    "    scoring=anomaly_scorer,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "random_search.fit(X_train)\n",
    "random_search_time = time.time() - random_search_start\n",
    "\n",
    "print(f\"Randomized Search completed in {random_search_time:.2f}s ({random_search_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c484a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Randomized Search results\n",
    "print(\"RANDOMIZED SEARCH RESULTS\")\n",
    "print(f\"\\nBest Score: {random_search.best_score_:.6f}\")\n",
    "print(f\"Best Parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create results dataframe\n",
    "random_results_df = pd.DataFrame(random_search.cv_results_)\n",
    "random_results_df = random_results_df.sort_values('rank_test_score')\n",
    "\n",
    "# Display top 10 parameter combinations\n",
    "print(\"\\nTop 10 Parameter Combinations:\")\n",
    "display_cols = ['rank_test_score', 'mean_test_score', 'std_test_score', 'mean_fit_time',\n",
    "                'param_n_estimators', 'param_contamination', 'param_max_samples', \n",
    "                'param_max_features', 'param_bootstrap']\n",
    "display(random_results_df[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Randomized Search results\n",
    "fig = model_viz.plot_random_search_results(random_results_df, random_search.best_score_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46d24d",
   "metadata": {},
   "source": [
    "## 6. Performance Comparison & Analysis\n",
    "\n",
    "Compare the results from baseline, grid search, and randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81256b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': ['Baseline', 'Grid Search', 'Randomized Search'],\n",
    "    'Best Score': [\n",
    "        'N/A (no CV)',\n",
    "        f\"{grid_search.best_score_:.6f}\",\n",
    "        f\"{random_search.best_score_:.6f}\"\n",
    "    ],\n",
    "    'Search Time (s)': [\n",
    "        baseline_train_time,\n",
    "        grid_search_time,\n",
    "        random_search_time\n",
    "    ],\n",
    "    'Configurations Tested': [\n",
    "        1,\n",
    "        len(grid_results_df),\n",
    "        len(random_results_df)\n",
    "    ],\n",
    "    'N Estimators': [\n",
    "        baseline_params['n_estimators'],\n",
    "        grid_search.best_params_['n_estimators'],\n",
    "        random_search.best_params_['n_estimators']\n",
    "    ],\n",
    "    'Contamination': [\n",
    "        baseline_params['contamination'],\n",
    "        grid_search.best_params_['contamination'],\n",
    "        random_search.best_params_['contamination']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"HYPERPARAMETER TUNING COMPARISON\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Determine best overall method\n",
    "if grid_search.best_score_ > random_search.best_score_:\n",
    "    best_method = 'Grid Search'\n",
    "    best_search = grid_search\n",
    "    best_score = grid_search.best_score_\n",
    "else:\n",
    "    best_method = 'Randomized Search'\n",
    "    best_search = random_search\n",
    "    best_score = random_search.best_score_\n",
    "\n",
    "print(f\"\\nBest Method: {best_method}\")\n",
    "print(f\"Score: {best_score:.6f}\")\n",
    "print(f\"\\nOptimal Parameters:\")\n",
    "for param, value in best_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da170c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig = model_viz.plot_search_comparison(\n",
    "    baseline_train_time, \n",
    "    grid_search_time, \n",
    "    random_search_time,\n",
    "    grid_results_df,\n",
    "    random_results_df\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c9bec",
   "metadata": {},
   "source": [
    "## 7. Final Model Training with Optimal Parameters\n",
    "\n",
    "Train the final optimized model using the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimal parameters from best search method\n",
    "optimal_params = best_search.best_params_.copy()\n",
    "optimal_params['random_state'] = 42\n",
    "optimal_params['n_jobs'] = -1\n",
    "optimal_params['verbose'] = 0\n",
    "\n",
    "print(\"Training final optimized model with best parameters...\")\n",
    "\n",
    "# Train final model\n",
    "final_start_time = time.time()\n",
    "\n",
    "optimized_model = IsolationForest(**optimal_params)\n",
    "optimized_model.fit(X_train)\n",
    "\n",
    "final_train_time = time.time() - final_start_time\n",
    "\n",
    "print(f\"Final model training completed in {final_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate optimized model\n",
    "optimized_train_scores = optimized_model.decision_function(X_train)\n",
    "optimized_test_scores = optimized_model.decision_function(X_test)\n",
    "optimized_train_preds = optimized_model.predict(X_train)\n",
    "optimized_test_preds = optimized_model.predict(X_test)\n",
    "\n",
    "optimized_train_anomalies = (optimized_train_preds == -1).sum()\n",
    "optimized_test_anomalies = (optimized_test_preds == -1).sum()\n",
    "\n",
    "# Calculate anomaly score statistics\n",
    "optimized_score_mean = optimized_test_scores.mean()\n",
    "optimized_score_std = optimized_test_scores.std()\n",
    "optimized_score_range = optimized_test_scores.max() - optimized_test_scores.min()\n",
    "\n",
    "print(\"OPTIMIZED MODEL PERFORMANCE\")\n",
    "print(f\"\\nTrain Anomalies: {optimized_train_anomalies:,}/{len(X_train):,} ({optimized_train_anomalies/len(X_train)*100:.2f}%)\")\n",
    "print(f\"Test Anomalies: {optimized_test_anomalies:,}/{len(X_test):,} ({optimized_test_anomalies/len(X_test)*100:.2f}%)\")\n",
    "print(f\"\\nScore Statistics (Test):\")\n",
    "print(f\"  Mean: {optimized_score_mean:.6f}\")\n",
    "print(f\"  Std: {optimized_score_std:.6f}\")\n",
    "print(f\"  Range: {optimized_score_range:.6f}\")\n",
    "print(f\"  Min: {optimized_test_scores.min():.6f}\")\n",
    "print(f\"  Max: {optimized_test_scores.max():.6f}\")\n",
    "print(f\"\\nTraining Time: {final_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbe2a9",
   "metadata": {},
   "source": [
    "## 8. Model Validation & Evaluation\n",
    "\n",
    "Compare baseline and optimized model performance side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fef5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed comparison\n",
    "model_comparison_df = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Train Time (s)',\n",
    "        'Train Anomalies',\n",
    "        'Train Anomaly %',\n",
    "        'Test Anomalies',\n",
    "        'Test Anomaly %',\n",
    "        'Test Score Mean',\n",
    "        'Test Score Std',\n",
    "        'Test Score Range',\n",
    "        'N Estimators',\n",
    "        'Contamination',\n",
    "        'Max Samples',\n",
    "        'Max Features',\n",
    "        'Bootstrap'\n",
    "    ],\n",
    "    'Baseline Model': [\n",
    "        f\"{baseline_train_time:.2f}\",\n",
    "        f\"{baseline_train_anomalies:,}\",\n",
    "        f\"{baseline_train_anomalies/len(X_train)*100:.2f}%\",\n",
    "        f\"{baseline_test_anomalies:,}\",\n",
    "        f\"{baseline_test_anomalies/len(X_test)*100:.2f}%\",\n",
    "        f\"{baseline_score_mean:.6f}\",\n",
    "        f\"{baseline_score_std:.6f}\",\n",
    "        f\"{baseline_score_range:.6f}\",\n",
    "        baseline_params['n_estimators'],\n",
    "        baseline_params['contamination'],\n",
    "        baseline_params['max_samples'],\n",
    "        baseline_params['max_features'],\n",
    "        baseline_params['bootstrap']\n",
    "    ],\n",
    "    'Optimized Model': [\n",
    "        f\"{final_train_time:.2f}\",\n",
    "        f\"{optimized_train_anomalies:,}\",\n",
    "        f\"{optimized_train_anomalies/len(X_train)*100:.2f}%\",\n",
    "        f\"{optimized_test_anomalies:,}\",\n",
    "        f\"{optimized_test_anomalies/len(X_test)*100:.2f}%\",\n",
    "        f\"{optimized_score_mean:.6f}\",\n",
    "        f\"{optimized_score_std:.6f}\",\n",
    "        f\"{optimized_score_range:.6f}\",\n",
    "        optimal_params['n_estimators'],\n",
    "        optimal_params['contamination'],\n",
    "        optimal_params.get('max_samples', 'auto'),\n",
    "        optimal_params.get('max_features', 1.0),\n",
    "        optimal_params.get('bootstrap', False)\n",
    "    ],\n",
    "    'Change': [\n",
    "        f\"{((final_train_time - baseline_train_time) / baseline_train_time * 100):+.1f}%\",\n",
    "        f\"{optimized_train_anomalies - baseline_train_anomalies:+,}\",\n",
    "        f\"{(optimized_train_anomalies/len(X_train) - baseline_train_anomalies/len(X_train))*100:+.2f}%\",\n",
    "        f\"{optimized_test_anomalies - baseline_test_anomalies:+,}\",\n",
    "        f\"{(optimized_test_anomalies/len(X_test) - baseline_test_anomalies/len(X_test))*100:+.2f}%\",\n",
    "        f\"{(optimized_score_mean - baseline_score_mean):+.6f}\",\n",
    "        f\"{(optimized_score_std - baseline_score_std):+.6f}\",\n",
    "        f\"{(optimized_score_range - baseline_score_range):+.6f}\",\n",
    "        f\"{optimal_params['n_estimators'] - baseline_params['n_estimators']:+d}\",\n",
    "        f\"{optimal_params['contamination'] - baseline_params['contamination']:+.2f}\",\n",
    "        '-',\n",
    "        '-',\n",
    "        '-'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"BASELINE vs OPTIMIZED MODEL COMPARISON\")\n",
    "display(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions comparison\n",
    "fig = model_viz.plot_model_comparison(\n",
    "    baseline_test_scores,\n",
    "    optimized_test_scores,\n",
    "    baseline_train_anomalies,\n",
    "    baseline_test_anomalies,\n",
    "    optimized_train_anomalies,\n",
    "    optimized_test_anomalies,\n",
    "    len(X_train),\n",
    "    len(X_test),\n",
    "    baseline_score_mean,\n",
    "    optimized_score_mean,\n",
    "    baseline_score_std,\n",
    "    optimized_score_std\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze detected anomalies from optimized model\n",
    "all_data = np.vstack([X_train, X_test])\n",
    "all_predictions = optimized_model.predict(all_data)\n",
    "all_scores = optimized_model.decision_function(all_data)\n",
    "\n",
    "anomaly_labels = (all_predictions == -1).astype(int)\n",
    "anomaly_count = anomaly_labels.sum()\n",
    "\n",
    "# Create results dataframe\n",
    "anomaly_results = df_payments.copy()\n",
    "anomaly_results['anomaly_score'] = all_scores\n",
    "anomaly_results['is_anomaly'] = anomaly_labels\n",
    "anomaly_results['anomaly_score_percentile'] = pd.Series(all_scores).rank(pct=True) * 100\n",
    "\n",
    "# Filter anomalies\n",
    "anomalies_df = anomaly_results[anomaly_results['is_anomaly'] == 1].copy()\n",
    "anomalies_df = anomalies_df.sort_values('anomaly_score', ascending=True)\n",
    "\n",
    "print(f\"Total Anomalies Detected: {anomaly_count:,} ({anomaly_count/len(anomaly_results)*100:.2f}%)\")\n",
    "\n",
    "# Display top anomalies\n",
    "print(\"\\nTop 10 Detected Anomalies:\")\n",
    "top_anomalies = model_viz.display_top_anomalies(\n",
    "    anomalies_df=anomalies_df,\n",
    "    score_col='anomaly_score',\n",
    "    top_n=10\n",
    ")\n",
    "display(top_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ae94b",
   "metadata": {},
   "source": [
    "## 9. Summary & Outputs\n",
    "\n",
    "Save the optimized model, results, and tuning summary for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6838ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized model\n",
    "optimized_model_path = 'cms_isolation_forest_optimized.pkl'\n",
    "with open(optimized_model_path, 'wb') as f:\n",
    "    pickle.dump(optimized_model, f)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = 'isolation_forest_scaler_optimized.pkl'\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save anomaly detection results\n",
    "results_path = 'anomaly_results_optimized.csv'\n",
    "anomaly_results.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"Saved: {optimized_model_path}, {scaler_path}, {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"HYPERPARAMETER TUNING SUMMARY\")\n",
    "print(f\"\\nBest Method: {best_method} | Score: {best_score:.6f}\")\n",
    "print(f\"Optimal Parameters: n_estimators={optimal_params['n_estimators']}, contamination={optimal_params['contamination']}\")\n",
    "\n",
    "improvement = ((baseline_train_time - final_train_time) / baseline_train_time * 100)\n",
    "if abs(improvement) > 5:\n",
    "    print(f\"Training Time: {final_train_time:.2f}s ({improvement:+.1f}% vs baseline)\")\n",
    "\n",
    "print(f\"\\nCompleted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fade38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables for downstream notebooks\n",
    "%store optimized_model\n",
    "%store optimal_params\n",
    "%store anomaly_results\n",
    "%store scaler\n",
    "\n",
    "print(\"Stored: optimized_model, optimal_params, anomaly_results, scaler\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
