{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed854a23",
   "metadata": {},
   "source": [
    "# Model Deployment & Inference with AWS SageMaker\n",
    "\n",
    "**Project:** AAI-540 Machine Learning Operations - Final Team Project  \n",
    "**Context:** Continuation of notebook 05 - Hyperparameter Tuning  \n",
    "**Objective:** Deploy optimized Isolation Forest model to AWS SageMaker for production inference\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Configuration](#setup)\n",
    "2. [Model Card Creation](#model-card)\n",
    "3. [Model Packaging for SageMaker](#packaging)\n",
    "4. [Model Registry & Versioning](#registry)\n",
    "5. [Endpoint Deployment](#deployment)\n",
    "6. [Inference Testing](#inference)\n",
    "7. [Performance Monitoring](#monitoring)\n",
    "8. [Summary & Cleanup](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2849e68",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "Load dependencies and configure AWS SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89398de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import tarfile\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "from utils.visualizations import ModelVisualizer\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "model_viz = ModelVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS SageMaker configuration\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = 'cms-anomaly-detection'\n",
    "\n",
    "# SageMaker clients\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "print(f\"Region: {region} | Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored variables from previous notebooks\n",
    "%store -r optimized_model\n",
    "%store -r optimal_params\n",
    "%store -r scaler\n",
    "%store -r df\n",
    "\n",
    "if 'optimized_model' not in dir() or optimized_model is None:\n",
    "    raise NameError(\"Missing required variable 'optimized_model'. Run notebook 05 first.\")\n",
    "    \n",
    "print(f\"Loaded: {type(optimized_model).__name__}, {type(scaler).__name__}, dataset {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c6931",
   "metadata": {},
   "source": [
    "## 2. Model Card Creation\n",
    "\n",
    "Create comprehensive model card documenting model details, performance, and intended use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model card\n",
    "model_card = {\n",
    "    \"model_details\": {\n",
    "        \"name\": \"CMS Open Payments Anomaly Detector\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"type\": \"Isolation Forest\",\n",
    "        \"framework\": \"scikit-learn\",\n",
    "        \"created_date\": datetime.now().strftime('%Y-%m-%d'),\n",
    "        \"created_by\": \"AAI-540 Team\"\n",
    "    },\n",
    "    \"intended_use\": {\n",
    "        \"primary_use\": \"Detect anomalous healthcare payment patterns\",\n",
    "        \"out_of_scope\": \"Not intended for automated decision-making without human review\"\n",
    "    },\n",
    "    \"model_parameters\": {\n",
    "        \"contamination\": optimal_params.get('contamination', 0.05),\n",
    "        \"n_estimators\": optimal_params.get('n_estimators', 200),\n",
    "        \"max_samples\": optimal_params.get('max_samples', 'auto'),\n",
    "        \"max_features\": optimal_params.get('max_features', 1.0)\n",
    "    },\n",
    "    \"training_data\": {\n",
    "        \"dataset\": \"CMS Open Payments 2024\",\n",
    "        \"preprocessing\": \"RobustScaler, IQR outlier clipping, median imputation\"\n",
    "    },\n",
    "    \"optimization\": {\n",
    "        \"method\": \"Grid Search and Randomized Search with 3-fold CV\",\n",
    "        \"metric\": \"Anomaly score separation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model card\n",
    "with open('model_card.json', 'w') as f:\n",
    "    json.dump(model_card, f, indent=2)\n",
    "\n",
    "print(\"Model card created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fec5a",
   "metadata": {},
   "source": [
    "## 3. Model Packaging for SageMaker\n",
    "\n",
    "Package the model and dependencies for SageMaker deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference script for SageMaker\n",
    "inference_script = \"\"\"import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \\\"\\\"\\\"Load model and scaler from model directory\\\"\\\"\\\" \n",
    "    model_path = os.path.join(model_dir, 'model.pkl')\n",
    "    scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "    \n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    return {'model': model, 'scaler': scaler}\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \\\"\\\"\\\"Parse input data\\\"\\\"\\\" \n",
    "    if request_content_type == 'application/json':\n",
    "        data = json.loads(request_body)\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported content type: {request_content_type}')\n",
    "\n",
    "def predict_fn(input_data, model_artifacts):\n",
    "    \\\"\\\"\\\"Generate predictions\\\"\\\"\\\" \n",
    "    model = model_artifacts['model']\n",
    "    scaler = model_artifacts['scaler']\n",
    "    \n",
    "    # Scale input data\n",
    "    scaled_data = scaler.transform(input_data)\n",
    "    \n",
    "    # Generate predictions and scores\n",
    "    predictions = model.predict(scaled_data)\n",
    "    scores = model.decision_function(scaled_data)\n",
    "    \n",
    "    # Convert predictions: -1 (anomaly) to 1, 1 (normal) to 0\n",
    "    anomaly_labels = (predictions == -1).astype(int).tolist()\n",
    "    \n",
    "    return {\n",
    "        'predictions': anomaly_labels,\n",
    "        'anomaly_scores': scores.tolist(),\n",
    "        'is_anomaly': predictions.tolist()\n",
    "    }\n",
    "\n",
    "def output_fn(prediction, response_content_type):\n",
    "    \\\"\\\"\\\"Format output\\\"\\\"\\\" \n",
    "    if response_content_type == 'application/json':\n",
    "        return json.dumps(prediction)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported content type: {response_content_type}')\n",
    "\"\"\"\n",
    "\n",
    "# Save inference script\n",
    "with open('inference.py', 'w') as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "print(\"Inference script created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory structure\n",
    "model_dir = Path('model_artifacts')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and scaler\n",
    "with open(model_dir / 'model.pkl', 'wb') as f:\n",
    "    pickle.dump(optimized_model, f)\n",
    "\n",
    "with open(model_dir / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Copy inference script and model card\n",
    "import shutil\n",
    "shutil.copy('inference.py', model_dir / 'inference.py')\n",
    "shutil.copy('model_card.json', model_dir / 'model_card.json')\n",
    "\n",
    "print(f\"Model artifacts prepared in {model_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tar.gz archive for SageMaker\n",
    "model_archive = 'model.tar.gz'\n",
    "\n",
    "with tarfile.open(model_archive, 'w:gz') as tar:\n",
    "    tar.add(model_dir, arcname='.')\n",
    "\n",
    "print(f\"Model archived: {model_archive} ({Path(model_archive).stat().st_size / 1024:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a427716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model archive to S3\n",
    "model_s3_key = f\"{s3_prefix}/models/{model_archive}\"\n",
    "model_s3_uri = f\"s3://{bucket}/{model_s3_key}\"\n",
    "\n",
    "s3_client.upload_file(model_archive, bucket, model_s3_key)\n",
    "\n",
    "print(f\"Model uploaded to S3: {model_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243fc4a",
   "metadata": {},
   "source": [
    "## 4. Model Registry & Versioning\n",
    "\n",
    "Register model in SageMaker Model Registry for versioning and lifecycle management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Package Group\n",
    "model_package_group_name = 'cms-anomaly-detection-models'\n",
    "\n",
    "try:\n",
    "    sagemaker_client.create_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelPackageGroupDescription='CMS Open Payments Anomaly Detection Models'\n",
    "    )\n",
    "    print(f\"Model Package Group created: {model_package_group_name}\")\n",
    "except sagemaker_client.exceptions.ResourceInUse:\n",
    "    print(f\"Model Package Group exists: {model_package_group_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker SKLearn Model\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    model_data=model_s3_uri,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    name=f\"cms-anomaly-model-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    ")\n",
    "\n",
    "print(f\"SKLearn Model: {sklearn_model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model version\n",
    "model_package_description = \"Optimized Isolation Forest model for CMS anomaly detection\"\n",
    "\n",
    "model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageDescription\": model_package_description,\n",
    "    \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"Image\": sklearn_model.image_uri,\n",
    "                \"ModelDataUrl\": model_s3_uri,\n",
    "            }\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"application/json\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "model_package_response = sagemaker_client.create_model_package(**model_package_input_dict)\n",
    "model_package_arn = model_package_response[\"ModelPackageArn\"]\n",
    "\n",
    "print(f\"Model registered with ARN: {model_package_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve model for deployment\n",
    "sagemaker_client.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\"\n",
    ")\n",
    "\n",
    "print(\"Model approved for deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136470b9",
   "metadata": {},
   "source": [
    "## 5. Endpoint Deployment\n",
    "\n",
    "Deploy model to SageMaker real-time inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02726f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to endpoint\n",
    "endpoint_name = f\"cms-anomaly-endpoint-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "print(f\"Deploying to endpoint: {endpoint_name} (5-10 minutes)...\")\n",
    "\n",
    "predictor = sklearn_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"Endpoint deployed: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint status\n",
    "endpoint_description = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {endpoint_description['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa93a86",
   "metadata": {},
   "source": [
    "## 6. Inference Testing\n",
    "\n",
    "Test the deployed endpoint with sample data and evaluate inference performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "test_sample = df.sample(n=100, random_state=42)\n",
    "\n",
    "# Select numeric features (same as training)\n",
    "numeric_cols = test_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cols_to_exclude = [\n",
    "    'EventTime', 'covered_recipient_profile_id', 'index',\n",
    "    'teaching_hospital_id', 'covered_recipient_npi',\n",
    "    'recipient_zip_code', 'recipient_province', 'recipient_postal_code'\n",
    "]\n",
    "numeric_features = [col for col in numeric_cols \n",
    "                   if col not in cols_to_exclude \n",
    "                   and not any(x in col.lower() for x in ['_id', '_code', '_province', '_postal'])]\n",
    "\n",
    "X_test_sample = test_sample[numeric_features].copy()\n",
    "X_test_sample = X_test_sample.fillna(X_test_sample.median())\n",
    "\n",
    "print(f\"Test sample prepared: {X_test_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single prediction\n",
    "single_record = X_test_sample.iloc[0:1].to_dict('records')\n",
    "\n",
    "start_time = time.time()\n",
    "response = predictor.predict(single_record)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"Single prediction: {inference_time*1000:.2f} ms\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch prediction\n",
    "batch_records = X_test_sample.to_dict('records')\n",
    "\n",
    "start_time = time.time()\n",
    "batch_response = predictor.predict(batch_records)\n",
    "batch_inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"Batch ({len(batch_records)} records): {batch_inference_time:.2f}s | {(batch_inference_time/len(batch_records))*1000:.2f} ms/record | {len(batch_records)/batch_inference_time:.2f} records/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e31221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze batch predictions\n",
    "predictions = batch_response['predictions']\n",
    "anomaly_scores = batch_response['anomaly_scores']\n",
    "\n",
    "anomaly_count = sum(predictions)\n",
    "anomaly_rate = (anomaly_count / len(predictions)) * 100\n",
    "\n",
    "print(f\"Results: {anomaly_count}/{len(predictions)} anomalies ({anomaly_rate:.2f}%)\")\n",
    "print(f\"Scores: mean={np.mean(anomaly_scores):.4f}, std={np.std(anomaly_scores):.4f}, range=[{np.min(anomaly_scores):.4f}, {np.max(anomaly_scores):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance testing - measure latency distribution\n",
    "latencies = []\n",
    "n_tests = 50\n",
    "\n",
    "for i in range(n_tests):\n",
    "    test_record = X_test_sample.sample(n=1).to_dict('records')\n",
    "    start = time.time()\n",
    "    _ = predictor.predict(test_record)\n",
    "    latencies.append((time.time() - start) * 1000)\n",
    "\n",
    "latency_stats = {\n",
    "    'Mean': np.mean(latencies),\n",
    "    'Median': np.median(latencies),\n",
    "    'P95': np.percentile(latencies, 95),\n",
    "    'P99': np.percentile(latencies, 99),\n",
    "    'Min': np.min(latencies),\n",
    "    'Max': np.max(latencies)\n",
    "}\n",
    "\n",
    "print(f\"Latency ({n_tests} tests): Mean={latency_stats['Mean']:.2f}ms, P95={latency_stats['P95']:.2f}ms, P99={latency_stats['P99']:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize latency distribution\n",
    "fig = model_viz.plot_latency_distribution(latencies, latency_stats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586df77e",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring\n",
    "\n",
    "Set up monitoring and logging for the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable data capture for monitoring\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=f\"s3://{bucket}/{s3_prefix}/data-capture\"\n",
    ")\n",
    "\n",
    "print(f\"Data capture enabled: s3://{bucket}/{s3_prefix}/data-capture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CloudWatch metrics configured for endpoint\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "print(\"CloudWatch monitoring: ModelLatency, ModelInvocations, ModelInvocation4XXErrors, ModelInvocation5XXErrors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d908ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment summary\n",
    "deployment_summary = pd.DataFrame({\n",
    "    'Component': [\n",
    "        'Model Type',\n",
    "        'Framework',\n",
    "        'Endpoint Name',\n",
    "        'Instance Type',\n",
    "        'Instance Count',\n",
    "        'Model S3 URI',\n",
    "        'Model Package ARN',\n",
    "        'Average Latency (ms)',\n",
    "        'P95 Latency (ms)',\n",
    "        'Throughput (records/sec)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        'Isolation Forest',\n",
    "        'scikit-learn 1.2-1',\n",
    "        endpoint_name,\n",
    "        'ml.m5.large',\n",
    "        '1',\n",
    "        model_s3_uri,\n",
    "        model_package_arn,\n",
    "        f\"{latency_stats['Mean']:.2f}\",\n",
    "        f\"{latency_stats['P95']:.2f}\",\n",
    "        f\"{len(batch_records)/batch_inference_time:.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Deployment Summary:\")\n",
    "display(deployment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e48e8",
   "metadata": {},
   "source": [
    "## 8. Summary & Cleanup\n",
    "\n",
    "Save deployment configuration and provide cleanup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save deployment configuration\n",
    "deployment_config = {\n",
    "    'endpoint_name': endpoint_name,\n",
    "    'model_package_arn': model_package_arn,\n",
    "    'model_s3_uri': model_s3_uri,\n",
    "    'region': region,\n",
    "    'bucket': bucket,\n",
    "    'deployment_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'instance_type': 'ml.m5.large',\n",
    "    'instance_count': 1,\n",
    "    'framework': 'scikit-learn',\n",
    "    'framework_version': '1.2-1'\n",
    "}\n",
    "\n",
    "with open('deployment_config.json', 'w') as f:\n",
    "    json.dump(deployment_config, f, indent=2)\n",
    "\n",
    "print(\"Deployment configuration saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables for downstream notebooks\n",
    "%store endpoint_name\n",
    "%store model_package_arn\n",
    "%store predictor\n",
    "%store deployment_config\n",
    "\n",
    "print(f\"Stored: endpoint_name, model_package_arn, predictor, deployment_config\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
