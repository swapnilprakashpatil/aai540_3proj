{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc95b1c",
   "metadata": {},
   "source": [
    "# Isolation Forest Anomaly Detection for CMS Open Payments\n",
    "\n",
    "**Project:** AAI-540 Machine Learning Operations - Final Team Project  \n",
    "**Context:** Continuation of notebook 02 - Data Exploration & Analysis  \n",
    "**Objective:** Train an Isolation Forest model to detect anomalous payment patterns using ensemble-based outlier detection\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Data Loading](#setup)\n",
    "2. [Load Data from Stored Variables](#loading)\n",
    "3. [Data Preparation & Feature Engineering](#preparation)\n",
    "4. [Isolation Forest Configuration](#configuration)\n",
    "5. [Model Training](#training)\n",
    "6. [Performance Evaluation](#evaluation)\n",
    "7. [Anomaly Score Calculation & Validation](#scoring)\n",
    "8. [Visualizations & Metrics](#visualizations)\n",
    "9. [Summary & Outputs](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ae4f0-fcf9-4059-ae31-43f4389dac41",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n",
    "\n",
    "Load dependencies and restore configuration from notebook 02 (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from S3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-04 09:42:12,465\tWARNING services.py:2070 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1938784256 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.18gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2026-02-04 09:42:12,603\tINFO worker.py:1852 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Dataframe shape: (1000000, 91)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import awswrangler as wr\n",
    "from datetime import datetime\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a252043",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r region\n",
    "%store -r database_name\n",
    "%store -r table_name_parquet\n",
    "%store -r s3_parquet_path\n",
    "%store -r s3_athena_staging\n",
    "%store -r df\n",
    "\n",
    "if 'df' not in dir() or df is None:\n",
    "    raise NameError(\"Missing required variable 'df'. Run notebook 02 first.\")\n",
    "    \n",
    "print(f\"Region: {region} | Bucket: {bucket} | Database: {database_name}\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195c8fb-74f3-4f92-835e-4c9c6995eaa3",
   "metadata": {},
   "source": [
    "## 2. Load Data from Stored Variables\n",
    "\n",
    "Use the cleaned and processed dataset from notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f63637-18ee-47c8-9a12-346f20d78750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Features restored. New shape: (1000000, 97)\n"
     ]
    }
   ],
   "source": [
    "df_payments = df.copy()\n",
    "display(df_payments.head(3))\n",
    "print(f\"Dataset loaded: {df_payments.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aeb170-9dcb-4993-bbb2-9f88c6cf228c",
   "metadata": {},
   "source": [
    "## 3. Data Preparation & Feature Engineering\n",
    "\n",
    "Prepare features for Isolation Forest training with appropriate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522f0c3-07ff-43c3-b00d-a222b251a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: X_train defined with 399617 rows.\n"
     ]
    }
   ],
   "source": [
    "# Select numeric features for anomaly detection\n",
    "numeric_cols = df_payments.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Exclude identifier and non-relevant columns\n",
    "cols_to_exclude = [\n",
    "    'EventTime', 'covered_recipient_profile_id', 'index',\n",
    "    'teaching_hospital_id', 'covered_recipient_npi',\n",
    "    'recipient_zip_code', 'recipient_province', 'recipient_postal_code'\n",
    "]\n",
    "\n",
    "numeric_features = [col for col in numeric_cols \n",
    "                   if col not in cols_to_exclude \n",
    "                   and not any(x in col.lower() for x in ['_id', '_code', '_province', '_postal'])]\n",
    "\n",
    "# Create feature matrix\n",
    "X = df_payments[numeric_features].copy().astype(float)\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Remove columns with excessive missing values (>50%)\n",
    "missing_pct = (X.isnull().sum() / len(X)) * 100\n",
    "cols_to_keep = missing_pct[missing_pct <= 50].index.tolist()\n",
    "X = X[cols_to_keep]\n",
    "\n",
    "# Handle outliers using IQR method\n",
    "for col in X.columns:\n",
    "    q1, q3 = X[col].quantile(0.25), X[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    X[col] = X[col].clip(lower=q1 - 3*iqr, upper=q3 + 3*iqr)\n",
    "\n",
    "# Fill remaining missing values with median\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Features prepared: {X.shape}\")\n",
    "print(f\"Selected features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d68492-d563-4822-9042-b79320e1fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline (Isolation Forest)...\n",
      "Baseline complete.\n",
      "Anomalies detected: 1402\n"
     ]
    }
   ],
   "source": [
    "# Scale features using RobustScaler (better for outliers)\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"Scaled data: {X_scaled.shape}\")\n",
    "print(f\"Range: [{X_scaled.min().min():.4f}, {X_scaled.max().max():.4f}]\")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192de60-2aae-494e-9cc0-1c3ee8dba565",
   "metadata": {},
   "source": [
    "## 4. Isolation Forest Configuration\n",
    "\n",
    "Configure the Isolation Forest model with optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be5f17-070d-4fe7-b72a-5820e6a9b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BASELINE PERFORMANCE SUMMARY ---\n",
      "Total Test Records: 99,866\n",
      "Anomalies Flagged: 1,402\n",
      "Anomaly Rate: 1.40%\n",
      "\n",
      "--- STATISTICAL VALIDATION ---\n",
      "Average Payment Amount:\n",
      "is_anomaly_baseline\n",
      "No     $11,216,779.51\n",
      "Yes           $317.87\n",
      "Name: total_amount_of_payment_usdollars, dtype: object\n",
      "\n",
      "Average Amount-to-Historical-Average Ratio:\n",
      "is_anomaly_baseline\n",
      "No     437840.39x\n",
      "Yes         7.86x\n",
      "Name: amt_to_avg_ratio, dtype: object\n",
      "\n",
      "--- TOP 5 MOST EXTREME ANOMALIES ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nature_of_payment_or_transfer_of_value</th>\n",
       "      <th>total_amount_of_payment_usdollars</th>\n",
       "      <th>amt_to_avg_ratio</th>\n",
       "      <th>scores_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283583</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>99.12</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>-0.092846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788962</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>77.41</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>-0.092846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97738</th>\n",
       "      <td>Travel and Lodging</td>\n",
       "      <td>598.94</td>\n",
       "      <td>0.204658</td>\n",
       "      <td>-0.086592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294667</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.083334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728268</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>126.39</td>\n",
       "      <td>0.076173</td>\n",
       "      <td>-0.083247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nature_of_payment_or_transfer_of_value  \\\n",
       "283583                          Entertainment   \n",
       "788962                      Food and Beverage   \n",
       "97738                      Travel and Lodging   \n",
       "294667                      Food and Beverage   \n",
       "728268                      Food and Beverage   \n",
       "\n",
       "        total_amount_of_payment_usdollars  amt_to_avg_ratio  scores_baseline  \n",
       "283583                              99.12          0.031592        -0.092846  \n",
       "788962                              77.41          0.024575        -0.092846  \n",
       "97738                              598.94          0.204658        -0.086592  \n",
       "294667                               2.63          0.000638        -0.083334  \n",
       "728268                             126.39          0.076173        -0.083247  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1770199681 on cpu 3 ***\n",
      "PC: @     0x7f03c0970e9e  (unknown)  epoll_wait\n",
      "    @     0x7f036c786b0d         64  absl::lts_20240722::AbslFailureSignalHandler()\n",
      "    @     0x7f03c088d520  (unknown)  (unknown)\n",
      "[2026-02-04 10:08:01,800 E 3439 3439] logging.cc:497: *** SIGTERM received at time=1770199681 on cpu 3 ***\n",
      "[2026-02-04 10:08:01,800 E 3439 3439] logging.cc:497: PC: @     0x7f03c0970e9e  (unknown)  epoll_wait\n",
      "[2026-02-04 10:08:01,801 E 3439 3439] logging.cc:497:     @     0x7f036c786b39         64  absl::lts_20240722::AbslFailureSignalHandler()\n",
      "[2026-02-04 10:08:01,801 E 3439 3439] logging.cc:497:     @     0x7f03c088d520  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest hyperparameters\n",
    "n_estimators = 200  # Number of trees in the forest\n",
    "contamination = 0.05  # Expected proportion of anomalies (5%)\n",
    "max_samples = 'auto'  # Number of samples to draw from X to train each tree\n",
    "random_state = 42\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Trees: {n_estimators}\")\n",
    "print(f\"  Contamination: {contamination}\")\n",
    "print(f\"  Max Samples: {max_samples}\")\n",
    "print(f\"  Random State: {random_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861ab41",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Train the Isolation Forest model on the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc43da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Isolation Forest\n",
    "isolation_forest = IsolationForest(\n",
    "    n_estimators=n_estimators,\n",
    "    contamination=contamination,\n",
    "    max_samples=max_samples,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Training Isolation Forest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model on training data\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6bd71c",
   "metadata": {},
   "source": [
    "## 6. Performance Evaluation\n",
    "\n",
    "Evaluate model performance and generate predictions on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and anomaly scores\n",
    "train_predictions = isolation_forest.predict(X_train)\n",
    "train_scores = isolation_forest.decision_function(X_train)\n",
    "\n",
    "test_predictions = isolation_forest.predict(X_test)\n",
    "test_scores = isolation_forest.decision_function(X_test)\n",
    "\n",
    "# Convert predictions: -1 (anomaly) to 1, 1 (normal) to 0\n",
    "train_anomalies = (train_predictions == -1).astype(int)\n",
    "test_anomalies = (test_predictions == -1).astype(int)\n",
    "\n",
    "train_anomaly_count = train_anomalies.sum()\n",
    "test_anomaly_count = test_anomalies.sum()\n",
    "\n",
    "print(f\"Train Anomalies: {train_anomaly_count:,}/{len(X_train):,} ({train_anomaly_count/len(X_train)*100:.2f}%)\")\n",
    "print(f\"Test Anomalies: {test_anomaly_count:,}/{len(X_test):,} ({test_anomaly_count/len(X_test)*100:.2f}%)\")\n",
    "print(f\"\\nScore Statistics:\")\n",
    "print(f\"  Train - Mean: {train_scores.mean():.4f} | Median: {np.median(train_scores):.4f} | Std: {train_scores.std():.4f}\")\n",
    "print(f\"  Test - Mean: {test_scores.mean():.4f} | Median: {np.median(test_scores):.4f} | Std: {test_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c98d28",
   "metadata": {},
   "source": [
    "## 7. Anomaly Score Calculation & Validation\n",
    "\n",
    "Calculate anomaly scores and validate detected anomalies with payment details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9519e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data for comprehensive analysis\n",
    "all_data = np.vstack([X_train, X_test])\n",
    "all_predictions = isolation_forest.predict(all_data)\n",
    "all_scores = isolation_forest.decision_function(all_data)\n",
    "\n",
    "# Calculate threshold (decision boundary)\n",
    "threshold = isolation_forest.offset_\n",
    "\n",
    "anomaly_labels = (all_predictions == -1).astype(int)\n",
    "anomaly_count = anomaly_labels.sum()\n",
    "anomaly_percentage = (anomaly_count / len(anomaly_labels)) * 100\n",
    "\n",
    "print(f\"Decision Threshold: {threshold:.6f}\")\n",
    "print(f\"Total Anomalies: {anomaly_count:,}/{len(anomaly_labels):,} ({anomaly_percentage:.2f}%)\")\n",
    "print(f\"Score Range: [{all_scores.min():.6f}, {all_scores.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fff31a",
   "metadata": {},
   "source": [
    "### Validation: Inspect Detected Anomalies\n",
    "\n",
    "Examine the payment details of detected anomalies to validate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe with anomaly scores\n",
    "anomaly_results = df_payments.copy()\n",
    "anomaly_results['anomaly_score'] = all_scores\n",
    "anomaly_results['is_anomaly'] = anomaly_labels\n",
    "anomaly_results['anomaly_score_percentile'] = pd.Series(all_scores).rank(pct=True) * 100\n",
    "\n",
    "# Filter anomalies and normal payments\n",
    "anomalies_df = anomaly_results[anomaly_results['is_anomaly'] == 1].copy()\n",
    "anomalies_df = anomalies_df.sort_values('anomaly_score', ascending=True)  # Lower scores = more anomalous\n",
    "normal_df = anomaly_results[anomaly_results['is_anomaly'] == 0]\n",
    "\n",
    "# Display key columns for top anomalies\n",
    "display_cols = [\n",
    "    'anomaly_score', \n",
    "    'anomaly_score_percentile',\n",
    "    'total_amount_of_payment_usdollars',\n",
    "    'covered_recipient_type',\n",
    "    'nature_of_payment_or_transfer_of_value'\n",
    "]\n",
    "\n",
    "# Add optional columns if they exist\n",
    "optional_cols = ['amt_to_avg_ratio', 'hist_pay_avg', 'is_new_recipient', \n",
    "                'is_weekend', 'is_high_risk_nature']\n",
    "for col in optional_cols:\n",
    "    if col in anomalies_df.columns:\n",
    "        display_cols.append(col)\n",
    "\n",
    "available_cols = [col for col in display_cols if col in anomalies_df.columns]\n",
    "print(f\"Top 10 Anomalous Payments (n={len(anomalies_df):,}):\")\n",
    "display(anomalies_df[available_cols].head(10))\n",
    "\n",
    "# Statistical comparison\n",
    "comparison_features = ['total_amount_of_payment_usdollars']\n",
    "optional_comparison = ['amt_to_avg_ratio', 'hist_pay_avg']\n",
    "for col in optional_comparison:\n",
    "    if col in anomaly_results.columns:\n",
    "        comparison_features.append(col)\n",
    "\n",
    "if comparison_features:\n",
    "    comparison_stats = pd.DataFrame({\n",
    "        'Normal_Mean': normal_df[comparison_features].mean(),\n",
    "        'Normal_Median': normal_df[comparison_features].median(),\n",
    "        'Anomaly_Mean': anomalies_df[comparison_features].mean(),\n",
    "        'Anomaly_Median': anomalies_df[comparison_features].median(),\n",
    "        'Difference_%': ((anomalies_df[comparison_features].mean() - normal_df[comparison_features].mean()) / \n",
    "                        normal_df[comparison_features].mean() * 100)\n",
    "    })\n",
    "    print(\"\\nStatistical Comparison:\")\n",
    "    display(comparison_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6859ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly distribution by key categories\n",
    "categorical_cols = ['covered_recipient_type', 'nature_of_payment_or_transfer_of_value']\n",
    "optional_categorical = ['is_high_risk_nature', 'is_weekend', 'is_new_recipient']\n",
    "\n",
    "for col in optional_categorical:\n",
    "    if col in anomalies_df.columns:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "categorical_cols = [col for col in categorical_cols if col in anomalies_df.columns]\n",
    "\n",
    "if categorical_cols:\n",
    "    print(\"\\nAnomaly Distribution by Category:\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(anomalies_df[col].value_counts().head(5))\n",
    "\n",
    "# Anomaly score statistics\n",
    "score_stats = pd.DataFrame({\n",
    "    'Metric': ['Mean', 'Median', 'Min', 'Max'],\n",
    "    'Normal': [\n",
    "        normal_df['anomaly_score'].mean(),\n",
    "        normal_df['anomaly_score'].median(),\n",
    "        normal_df['anomaly_score'].min(),\n",
    "        normal_df['anomaly_score'].max()\n",
    "    ],\n",
    "    'Anomaly': [\n",
    "        anomalies_df['anomaly_score'].mean(),\n",
    "        anomalies_df['anomaly_score'].median(),\n",
    "        anomalies_df['anomaly_score'].min(),\n",
    "        anomalies_df['anomaly_score'].max()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nAnomaly Score Statistics:\")\n",
    "display(score_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ef493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize payment amount distribution: Normal vs Anomalies\n",
    "if 'total_amount_of_payment_usdollars' in anomaly_results.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    normal_amounts = normal_df['total_amount_of_payment_usdollars']\n",
    "    anomaly_amounts = anomalies_df['total_amount_of_payment_usdollars']\n",
    "    \n",
    "    # Histogram comparison\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(normal_amounts, bins=50, alpha=0.6, label='Normal', color='blue', edgecolor='black')\n",
    "    ax1.hist(anomaly_amounts, bins=50, alpha=0.6, label='Anomalies', color='red', edgecolor='black')\n",
    "    ax1.set_xlabel('Payment Amount (USD)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Payment Amount Distribution: Normal vs Anomalies', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot comparison\n",
    "    ax2 = axes[1]\n",
    "    data_to_plot = [normal_amounts, anomaly_amounts]\n",
    "    bp = ax2.boxplot(data_to_plot, labels=['Normal', 'Anomalies'], \n",
    "                     patch_artist=True, widths=0.6)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    ax2.set_ylabel('Payment Amount (USD)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Payment Amount Box Plot Comparison', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5cb55",
   "metadata": {},
   "source": [
    "## 8. Visualizations & Metrics\n",
    "\n",
    "Visualize anomaly scores, distributions, and model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40950a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Anomaly score distribution by class\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(normal_df['anomaly_score'], bins=50, alpha=0.7, label='Normal', color='blue', edgecolor='black')\n",
    "ax1.hist(anomalies_df['anomaly_score'], bins=50, alpha=0.7, label='Anomalies', color='red', edgecolor='black')\n",
    "ax1.axvline(threshold, color='green', linestyle='--', linewidth=2.5, label=f'Threshold')\n",
    "ax1.set_xlabel('Anomaly Score', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Anomaly Score Distribution by Class', fontsize=12, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Train vs Test score distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(train_scores, bins=50, alpha=0.7, label='Train', color='purple', edgecolor='black')\n",
    "ax2.hist(test_scores, bins=50, alpha=0.7, label='Test', color='orange', edgecolor='black')\n",
    "ax2.axvline(threshold, color='green', linestyle='--', linewidth=2.5, label='Threshold')\n",
    "ax2.set_xlabel('Anomaly Score', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Train vs Test Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Anomaly count comparison\n",
    "ax3 = axes[1, 0]\n",
    "categories = ['Train', 'Test', 'Overall']\n",
    "anomaly_counts = [train_anomaly_count, test_anomaly_count, anomaly_count]\n",
    "normal_counts = [len(X_train) - train_anomaly_count, \n",
    "                len(X_test) - test_anomaly_count,\n",
    "                len(anomaly_labels) - anomaly_count]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x - width/2, normal_counts, width, label='Normal', color='lightblue', edgecolor='black')\n",
    "bars2 = ax3.bar(x + width/2, anomaly_counts, width, label='Anomalies', color='lightcoral', edgecolor='black')\n",
    "\n",
    "ax3.set_xlabel('Dataset', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Anomaly vs Normal Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(categories)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Percentile distribution\n",
    "ax4 = axes[1, 1]\n",
    "percentiles = np.arange(1, 101)\n",
    "ax4.plot(percentiles, np.percentile(all_scores, percentiles), \n",
    "        linewidth=2.5, color='darkblue', marker='o', markersize=3)\n",
    "ax4.axhline(y=threshold, color='red', linestyle='--', linewidth=2.5, \n",
    "           label=f'Threshold: {threshold:.6f}')\n",
    "ax4.fill_between(percentiles, threshold, np.percentile(all_scores, percentiles), \n",
    "                where=(np.percentile(all_scores, percentiles) < threshold),\n",
    "                alpha=0.3, color='red', label='Anomaly Region')\n",
    "ax4.set_xlabel('Percentile', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Anomaly Score', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Anomaly Score Percentile Distribution', fontsize=12, fontweight='bold')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe4668",
   "metadata": {},
   "source": [
    "## 9. Summary & Outputs\n",
    "\n",
    "Save model and anomaly detection results for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b00621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = 'cms_isolation_forest_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(isolation_forest, f)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = 'isolation_forest_scaler.pkl'\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save anomaly results\n",
    "results_path = 'anomaly_results_isolation_forest.csv'\n",
    "anomaly_results.to_csv(results_path, index=False)\n",
    "print(f\"Results saved: {results_path}\")\n",
    "\n",
    "# Create execution summary\n",
    "results_summary = pd.DataFrame({\n",
    "    'Metric': ['Total Records', 'Train Records', 'Test Records',\n",
    "               'Anomalies Detected', 'Anomaly Percentage', \n",
    "               'Decision Threshold', 'Mean Score', 'Training Time (sec)',\n",
    "               'N Estimators', 'Contamination'],\n",
    "    'Value': [len(anomaly_labels), len(X_train), len(X_test),\n",
    "              anomaly_count, f'{anomaly_percentage:.2f}%',\n",
    "              f'{threshold:.6f}', f'{all_scores.mean():.6f}',\n",
    "              f'{training_time:.2f}', n_estimators, contamination]\n",
    "})\n",
    "\n",
    "print(\"\\nExecution Summary:\")\n",
    "display(results_summary)\n",
    "\n",
    "# Feature importance (based on anomaly detection contribution)\n",
    "print(\"\\nFeatures Used in Model:\")\n",
    "for i, feat in enumerate(X.columns, 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for next notebook\n",
    "%store anomaly_results\n",
    "%store threshold\n",
    "%store isolation_forest\n",
    "\n",
    "print(\"Variables stored for next notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
