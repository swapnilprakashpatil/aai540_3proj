{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc95b1c",
   "metadata": {},
   "source": [
    "# CMS Open Payments Data Exploration & Analysis\n",
    "\n",
    "**Project:** AAI-540 Machine Learning Operations - Final Team Project  \n",
    "**Dataset:** CMS Open Payments Program Year 2024 General Payments  \n",
    "**Purpose:** Exploratory Data Analysis for Payment Patterns and Statistical Insights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ae4f0-fcf9-4059-ae31-43f4389dac41",
   "metadata": {},
   "source": [
    "## Environment Setup and Variable Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca9bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from S3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-04 09:42:12,465\tWARNING services.py:2070 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1938784256 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.18gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2026-02-04 09:42:12,603\tINFO worker.py:1852 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Dataframe shape: (1000000, 91)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awswrangler as wr\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# retrieve the path variables from Notebook 01\n",
    "%store -r bucket\n",
    "%store -r database_name\n",
    "%store -r table_name_parquet\n",
    "\n",
    "# reload the cleaned dataset from S3\n",
    "# This ensures 'df' is defined in this notebook's memory\n",
    "print(\"Loading processed data from S3...\")\n",
    "df = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT * FROM {database_name}.{table_name_parquet}\",\n",
    "    database=database_name\n",
    ")\n",
    "\n",
    "print(f\"Environment ready. Dataframe shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195c8fb-74f3-4f92-835e-4c9c6995eaa3",
   "metadata": {},
   "source": [
    "## Feature Selection and Matrix Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f63637-18ee-47c8-9a12-346f20d78750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Features restored. New shape: (1000000, 97)\n"
     ]
    }
   ],
   "source": [
    "# restore feature and dataset splits\n",
    "\n",
    "# turn non-date strings into NaT to prevent crashing\n",
    "df['date_of_payment'] = pd.to_datetime(df['date_of_payment'], errors='coerce')\n",
    "\n",
    "# check if we have too many NaTs (indicating a major schema shift)\n",
    "nan_dates = df['date_of_payment'].isna().sum()\n",
    "if nan_dates > 0:\n",
    "    print(f\"Warning: {nan_dates} rows had invalid date formats and were set to NaT.\")\n",
    "\n",
    "# fill NaT with a placeholder\n",
    "df['date_of_payment'] = df['date_of_payment'].ffill().bfill()\n",
    "\n",
    "df['payment_month'] = df['date_of_payment'].dt.month\n",
    "df['is_weekend'] = (df['date_of_payment'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "print(f\"Success: Features restored. New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aeb170-9dcb-4993-bbb2-9f88c6cf228c",
   "metadata": {},
   "source": [
    "## Baseline Model: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d522f0c3-07ff-43c3-b00d-a222b251a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: X_train defined with 399617 rows.\n"
     ]
    }
   ],
   "source": [
    "# define model features (must match what we restored in Block 2)\n",
    "model_features = [\n",
    "    'total_amount_of_payment_usdollars', 'hist_pay_avg', \n",
    "    'amt_to_avg_ratio', 'is_new_recipient', 'payment_month', 'is_weekend'\n",
    "]\n",
    "\n",
    "# create Train/Test splits using the restored 'dataset_usage' column\n",
    "train_df = df[df['dataset_usage'] == 'train'].copy()\n",
    "test_df = df[df['dataset_usage'] == 'test'].copy()\n",
    "\n",
    "# this creates the 'X_train' and 'X_test' variables the model is looking for\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(train_df[model_features])\n",
    "X_test = scaler.transform(test_df[model_features])\n",
    "\n",
    "print(f\"Success: X_train defined with {X_train.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d68492-d563-4822-9042-b79320e1fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline (Isolation Forest)...\n",
      "Baseline complete.\n",
      "Anomalies detected: 1402\n"
     ]
    }
   ],
   "source": [
    "# initialize the baseline\n",
    "baseline_model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "\n",
    "# fit on the matrices we prepared in the Scaling block\n",
    "print(\"Training Baseline (Isolation Forest)...\")\n",
    "baseline_model.fit(X_train)\n",
    "\n",
    "# predict on the test set\n",
    "# We use 'baseline' suffixes so we can compare models later\n",
    "test_df['scores_baseline'] = baseline_model.decision_function(X_test)\n",
    "test_df['is_anomaly_baseline'] = baseline_model.predict(X_test)\n",
    "\n",
    "# map to Yes/No\n",
    "test_df['is_anomaly_baseline'] = test_df['is_anomaly_baseline'].map({-1: 'Yes', 1: 'No'})\n",
    "\n",
    "print(\"Baseline complete.\")\n",
    "print(f\"Anomalies detected: {test_df[test_df['is_anomaly_baseline'] == 'Yes'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192de60-2aae-494e-9cc0-1c3ee8dba565",
   "metadata": {},
   "source": [
    "## Baseline Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0be5f17-070d-4fe7-b72a-5820e6a9b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BASELINE PERFORMANCE SUMMARY ---\n",
      "Total Test Records: 99,866\n",
      "Anomalies Flagged: 1,402\n",
      "Anomaly Rate: 1.40%\n",
      "\n",
      "--- STATISTICAL VALIDATION ---\n",
      "Average Payment Amount:\n",
      "is_anomaly_baseline\n",
      "No     $11,216,779.51\n",
      "Yes           $317.87\n",
      "Name: total_amount_of_payment_usdollars, dtype: object\n",
      "\n",
      "Average Amount-to-Historical-Average Ratio:\n",
      "is_anomaly_baseline\n",
      "No     437840.39x\n",
      "Yes         7.86x\n",
      "Name: amt_to_avg_ratio, dtype: object\n",
      "\n",
      "--- TOP 5 MOST EXTREME ANOMALIES ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nature_of_payment_or_transfer_of_value</th>\n",
       "      <th>total_amount_of_payment_usdollars</th>\n",
       "      <th>amt_to_avg_ratio</th>\n",
       "      <th>scores_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283583</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>99.12</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>-0.092846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788962</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>77.41</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>-0.092846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97738</th>\n",
       "      <td>Travel and Lodging</td>\n",
       "      <td>598.94</td>\n",
       "      <td>0.204658</td>\n",
       "      <td>-0.086592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294667</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.083334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728268</th>\n",
       "      <td>Food and Beverage</td>\n",
       "      <td>126.39</td>\n",
       "      <td>0.076173</td>\n",
       "      <td>-0.083247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nature_of_payment_or_transfer_of_value  \\\n",
       "283583                          Entertainment   \n",
       "788962                      Food and Beverage   \n",
       "97738                      Travel and Lodging   \n",
       "294667                      Food and Beverage   \n",
       "728268                      Food and Beverage   \n",
       "\n",
       "        total_amount_of_payment_usdollars  amt_to_avg_ratio  scores_baseline  \n",
       "283583                              99.12          0.031592        -0.092846  \n",
       "788962                              77.41          0.024575        -0.092846  \n",
       "97738                              598.94          0.204658        -0.086592  \n",
       "294667                               2.63          0.000638        -0.083334  \n",
       "728268                             126.39          0.076173        -0.083247  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1770199681 on cpu 3 ***\n",
      "PC: @     0x7f03c0970e9e  (unknown)  epoll_wait\n",
      "    @     0x7f036c786b0d         64  absl::lts_20240722::AbslFailureSignalHandler()\n",
      "    @     0x7f03c088d520  (unknown)  (unknown)\n",
      "[2026-02-04 10:08:01,800 E 3439 3439] logging.cc:497: *** SIGTERM received at time=1770199681 on cpu 3 ***\n",
      "[2026-02-04 10:08:01,800 E 3439 3439] logging.cc:497: PC: @     0x7f03c0970e9e  (unknown)  epoll_wait\n",
      "[2026-02-04 10:08:01,801 E 3439 3439] logging.cc:497:     @     0x7f036c786b39         64  absl::lts_20240722::AbslFailureSignalHandler()\n",
      "[2026-02-04 10:08:01,801 E 3439 3439] logging.cc:497:     @     0x7f03c088d520  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "# calculate the outlier Intensity\n",
    "# the lower the decision_score, the more 'isolated' or extreme the payment is\n",
    "print(f\"--- BASELINE PERFORMANCE SUMMARY ---\")\n",
    "print(f\"Total Test Records: {len(test_df):,}\")\n",
    "print(f\"Anomalies Flagged: {test_df[test_df['is_anomaly_baseline'] == 'Yes'].shape[0]:,}\")\n",
    "print(f\"Anomaly Rate: {(test_df['is_anomaly_baseline'] == 'Yes').mean():.2%}\")\n",
    "\n",
    "# statistical Validation: Do anomalies look different?\n",
    "# we compare the average payment of 'Normal' vs 'Anomaly'\n",
    "comparison = test_df.groupby('is_anomaly_baseline')[['total_amount_of_payment_usdollars', 'amt_to_avg_ratio']].mean()\n",
    "\n",
    "print(\"\\n--- STATISTICAL VALIDATION ---\")\n",
    "print(\"Average Payment Amount:\")\n",
    "print(comparison['total_amount_of_payment_usdollars'].map('${:,.2f}'.format))\n",
    "\n",
    "print(\"\\nAverage Amount-to-Historical-Average Ratio:\")\n",
    "print(comparison['amt_to_avg_ratio'].map('{:.2f}x'.format))\n",
    "\n",
    "# top 5 most extreme anomalies\n",
    "print(\"\\n--- TOP 5 MOST EXTREME ANOMALIES ---\")\n",
    "top_red_flags = test_df[test_df['is_anomaly_baseline'] == 'Yes'].sort_values('scores_baseline').head(5)\n",
    "\n",
    "display(top_red_flags[[\n",
    "    'nature_of_payment_or_transfer_of_value', \n",
    "    'total_amount_of_payment_usdollars', \n",
    "    'amt_to_avg_ratio', \n",
    "    'scores_baseline'\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779e8b8-e378-4b0a-8ccc-bdb7c765c715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
